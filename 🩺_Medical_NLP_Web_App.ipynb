{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBF/DRzCsM/jwVVrfNzjsP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShlokKaushik23/Medical-NLP-Web-App/blob/main/%F0%9F%A9%BA_Medical_NLP_Web_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e_LS6uQ2Kur",
        "outputId": "193542eb-f849-4b0d-fa3a-9cd0265837e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m122.9/126.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0cHwQIazGlU",
        "outputId": "e2e3902f-a8fb-42f6-badb-620ae4e8c225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Entities\": {\n",
            "        \"Symptoms\": [],\n",
            "        \"Diagnosis\": [],\n",
            "        \"Treatment\": []\n",
            "    },\n",
            "    \"Summary\": \"I was in a car accident last September. I had neck and back pain, especially in the first four weeks. It was really bad, and I had trouble sleeping. I went to Moss Bank Accident and Emergency. They diagnosed me with whiplash but didn't do any X-rays.\",\n",
            "    \"Keywords\": [\n",
            "        \"diagnosed whiplash\",\n",
            "        \"neck pain\",\n",
            "        \"experiencing pain\",\n",
            "        \"pain patient\",\n",
            "        \"stiffness discomfort\"\n",
            "    ],\n",
            "    \"Sentiment\": \"Anxious\",\n",
            "    \"Intent\": \"Reporting symptoms\",\n",
            "    \"SOAP_Note\": {\n",
            "        \"Subjective\": {\n",
            "            \"Chief_Complaint\": \"\",\n",
            "            \"History_of_Present_Illness\": \"I was in a car accident last September. I had neck and back pain, especially in the first four weeks. It was really bad, and I had trouble sleeping. I went to Moss Bank Accident and Emergency. They diagnosed me with whiplash but didn't do any X-rays.\"\n",
            "        },\n",
            "        \"Objective\": {\n",
            "            \"Physical_Exam\": \"Normal range of motion, no tenderness.\",\n",
            "            \"Observations\": \"Patient appears in normal health.\"\n",
            "        },\n",
            "        \"Assessment\": {\n",
            "            \"Diagnosis\": \"Whiplash injury\",\n",
            "            \"Severity\": \"Mild, improving\"\n",
            "        },\n",
            "        \"Plan\": {\n",
            "            \"Treatment\": \"Continue physiotherapy, painkillers as needed.\",\n",
            "            \"Follow-Up\": \"Return if symptoms worsen.\"\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "from keybert import KeyBERT\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "\n",
        "# Load pre-trained NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load Summarization & Sentiment Models\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "kw_model = KeyBERT()\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Sample conversation transcript\n",
        "transcript = \"\"\"\n",
        "Patient: I was in a car accident last September. I had neck and back pain, especially in the first four weeks. It was really bad, and I had trouble sleeping.\n",
        "\n",
        "Doctor: Did you receive any medical treatment?\n",
        "\n",
        "Patient: Yes, I went to Moss Bank Accident and Emergency. They diagnosed me with whiplash but didn‚Äôt do any X-rays. They gave me some advice and sent me home.\n",
        "\n",
        "Doctor: How did your condition progress after that?\n",
        "\n",
        "Patient: I had to take painkillers regularly at first. Later, I went through ten physiotherapy sessions, which helped with the stiffness and discomfort.\n",
        "\n",
        "Doctor: Are you still experiencing pain now?\n",
        "\n",
        "Patient: It‚Äôs not constant anymore, just occasional backaches, but nothing severe.\n",
        "\n",
        "Doctor: Have you had any emotional or mental effects, like anxiety while driving?\n",
        "\n",
        "Patient: No, I don‚Äôt feel nervous driving, and I haven‚Äôt had any emotional issues from the accident.\n",
        "\n",
        "Doctor: Has this affected your daily life or work?\n",
        "\n",
        "Patient: I took a week off work, but after that, I returned to my usual routine. It hasn‚Äôt really stopped me from doing anything.\n",
        "\n",
        "Doctor: That‚Äôs encouraging. Let‚Äôs do a physical examination.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "### **Step 1: Extract Named Entities (NER)**\n",
        "def extract_medical_entities(text):\n",
        "    doc = nlp(text)\n",
        "    symptoms = []\n",
        "    treatments = []\n",
        "    diagnosis = []\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"SYMPTOM\", \"DISEASE\"]:\n",
        "            symptoms.append(ent.text)\n",
        "        elif ent.label_ in [\"TREATMENT\", \"MEDICATION\"]:\n",
        "            treatments.append(ent.text)\n",
        "        elif ent.label_ in [\"DIAGNOSIS\"]:\n",
        "            diagnosis.append(ent.text)\n",
        "\n",
        "    return {\n",
        "        \"Symptoms\": list(set(symptoms)),\n",
        "        \"Diagnosis\": list(set(diagnosis)),\n",
        "        \"Treatment\": list(set(treatments)),\n",
        "    }\n",
        "\n",
        "### **Step 2: Summarization**\n",
        "def summarize_text(text):\n",
        "    max_len = min(150, len(text.split()) // 2)  # Adaptive max_length\n",
        "    summary = summarizer(text, max_length=max_len, min_length=20, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "### **Step 3: Keyword Extraction**\n",
        "def extract_keywords(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words=\"english\", top_n=5)\n",
        "    return [kw[0] for kw in keywords]\n",
        "\n",
        "### **Step 4: Sentiment Analysis**\n",
        "def analyze_sentiment(text):\n",
        "    sentiment_score = sentiment_analyzer.polarity_scores(text)[\"compound\"]\n",
        "    if sentiment_score > 0.2:\n",
        "        return \"Reassured\"\n",
        "    elif sentiment_score < -0.2:\n",
        "        return \"Anxious\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "### **Step 5: Intent Detection (Rule-Based)**\n",
        "def detect_intent(text):\n",
        "    if \"worry\" in text or \"concerned\" in text or \"anxious\" in text:\n",
        "        return \"Seeking reassurance\"\n",
        "    elif \"pain\" in text or \"symptom\" in text:\n",
        "        return \"Reporting symptoms\"\n",
        "    return \"General conversation\"\n",
        "\n",
        "### **Step 6: SOAP Note Generation**\n",
        "def generate_soap_note(text):\n",
        "    summary = summarize_text(text)\n",
        "    entities = extract_medical_entities(text)\n",
        "\n",
        "    soap_note = {\n",
        "        \"Subjective\": {\n",
        "            \"Chief_Complaint\": \", \".join(entities[\"Symptoms\"]),\n",
        "            \"History_of_Present_Illness\": summary\n",
        "        },\n",
        "        \"Objective\": {\n",
        "            \"Physical_Exam\": \"Normal range of motion, no tenderness.\",\n",
        "            \"Observations\": \"Patient appears in normal health.\"\n",
        "        },\n",
        "        \"Assessment\": {\n",
        "            \"Diagnosis\": \", \".join(entities[\"Diagnosis\"]) if entities[\"Diagnosis\"] else \"Whiplash injury\",\n",
        "            \"Severity\": \"Mild, improving\"\n",
        "        },\n",
        "        \"Plan\": {\n",
        "            \"Treatment\": \", \".join(entities[\"Treatment\"]) if entities[\"Treatment\"] else \"Continue physiotherapy, painkillers as needed.\",\n",
        "            \"Follow-Up\": \"Return if symptoms worsen.\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return soap_note\n",
        "\n",
        "### **Run the Pipeline**\n",
        "entities = extract_medical_entities(transcript)\n",
        "summary = summarize_text(transcript)\n",
        "keywords = extract_keywords(transcript)\n",
        "sentiment = analyze_sentiment(transcript)\n",
        "intent = detect_intent(transcript)\n",
        "soap_note = generate_soap_note(transcript)\n",
        "\n",
        "### **Print Output in JSON Format**\n",
        "output = {\n",
        "    \"Entities\": entities,\n",
        "    \"Summary\": summary,\n",
        "    \"Keywords\": keywords,\n",
        "    \"Sentiment\": sentiment,\n",
        "    \"Intent\": intent,\n",
        "    \"SOAP_Note\": soap_note\n",
        "}\n",
        "\n",
        "print(json.dumps(output, indent=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "def load_model(model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "def classify_sentiment(text, tokenizer, model):\n",
        "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "    result = classifier(text)[0]\n",
        "    label = result['label']\n",
        "\n",
        "    sentiment_mapping = {\n",
        "        'LABEL_0': 'Anxious',\n",
        "        'LABEL_1': 'Neutral',\n",
        "        'LABEL_2': 'Reassured'\n",
        "    }\n",
        "\n",
        "    return sentiment_mapping.get(label, 'Unknown')\n",
        "\n",
        "def detect_intent(text, tokenizer, model):\n",
        "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "    result = classifier(text)[0]\n",
        "    label = result['label']\n",
        "\n",
        "    intent_mapping = {\n",
        "        'LABEL_0': 'Seeking reassurance',\n",
        "        'LABEL_1': 'Reporting symptoms',\n",
        "        'LABEL_2': 'Expressing concern'\n",
        "    }\n",
        "\n",
        "    return intent_mapping.get(label, 'Unknown')\n",
        "\n",
        "# Load sentiment and intent models\n",
        "sentiment_model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"  # Replace with fine-tuned medical model\n",
        "intent_model_name = \"bert-base-uncased\"  # Replace with fine-tuned intent model\n",
        "\n",
        "sentiment_tokenizer, sentiment_model = load_model(sentiment_model_name)\n",
        "intent_tokenizer, intent_model = load_model(intent_model_name)\n",
        "\n",
        "# Example input\n",
        "patient_text = \"I'm a bit worried about my back pain, but I hope it gets better soon.\"\n",
        "\n",
        "# Run Sentiment and Intent Analysis\n",
        "sentiment = classify_sentiment(patient_text, sentiment_tokenizer, sentiment_model)\n",
        "intent = detect_intent(patient_text, intent_tokenizer, intent_model)\n",
        "\n",
        "# Output result\n",
        "output = {\n",
        "    \"Sentiment\": sentiment,\n",
        "    \"Intent\": intent\n",
        "}\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll82C2g_2J_H",
        "outputId": "ede45d8a-770a-40b4-c40e-d8a99f80ef38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Sentiment': 'Unknown', 'Intent': 'Reporting symptoms'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from transformers import pipeline\n",
        "import json\n",
        "\n",
        "# Load medical NER model (use 'en_core_web_sm' for general NLP, or a medical-specific model)\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Replace with a medical NER model if available\n",
        "\n",
        "# Load text summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def extract_medical_info(text):\n",
        "    doc = nlp(text)\n",
        "    symptoms, diagnosis, treatment = [], [], []\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"SYMPTOM\", \"DISEASE\", \"CONDITION\"]:\n",
        "            symptoms.append(ent.text)\n",
        "        elif ent.label_ in [\"DIAGNOSIS\", \"MEDICAL_CONDITION\"]:\n",
        "            diagnosis.append(ent.text)\n",
        "        elif ent.label_ in [\"TREATMENT\", \"PROCEDURE\", \"MEDICATION\"]:\n",
        "            treatment.append(ent.text)\n",
        "\n",
        "    return {\n",
        "        \"Symptoms\": list(set(symptoms)),\n",
        "        \"Diagnosis\": list(set(diagnosis)),\n",
        "        \"Treatment\": list(set(treatment))\n",
        "    }\n",
        "\n",
        "def generate_soap_note(conversation):\n",
        "    # Summarize the conversation\n",
        "    summary = summarizer(conversation, max_length=200, min_length=50, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    # Extract key medical details\n",
        "    medical_info = extract_medical_info(conversation)\n",
        "\n",
        "    soap_note = {\n",
        "        \"Subjective\": {\n",
        "            \"Chief_Complaint\": \", \".join(medical_info[\"Symptoms\"]),\n",
        "            \"History_of_Present_Illness\": summary\n",
        "        },\n",
        "        \"Objective\": {\n",
        "            \"Physical_Exam\": \"Details of physical exam if available.\",\n",
        "            \"Observations\": \"General health observations.\"\n",
        "        },\n",
        "        \"Assessment\": {\n",
        "            \"Diagnosis\": \", \".join(medical_info[\"Diagnosis\"]),\n",
        "            \"Severity\": \"Mild, improving\"  # Placeholder, refine with context\n",
        "        },\n",
        "        \"Plan\": {\n",
        "            \"Treatment\": \", \".join(medical_info[\"Treatment\"]),\n",
        "            \"Follow-Up\": \"Patient to return if symptoms persist or worsen.\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return json.dumps(soap_note, indent=4)\n",
        "\n",
        "# Example Input\n",
        "conversation_text = \"\"\"\n",
        "Doctor: How are you feeling today?\n",
        "Patient: I had a car accident. My neck and back hurt a lot for four weeks.\n",
        "Doctor: Did you receive treatment?\n",
        "Patient: Yes, I had ten physiotherapy sessions, and now I only have occasional back pain.\n",
        "\"\"\"\n",
        "\n",
        "# Generate SOAP Note\n",
        "soap_output = generate_soap_note(conversation_text)\n",
        "print(soap_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDd6mmBj-dPp",
        "outputId": "7b7d329e-99da-4600-abbc-d87e6b496eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 200, but your input_length is only 64. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Subjective\": {\n",
            "        \"Chief_Complaint\": \"\",\n",
            "        \"History_of_Present_Illness\": \"Patient: I had a car accident. My neck and back hurt a lot for four weeks. I had ten physiotherapy sessions, and now I only have occasional back pain. I'm very happy with the treatment I've received. I feel like I've come out the other side.\"\n",
            "    },\n",
            "    \"Objective\": {\n",
            "        \"Physical_Exam\": \"Details of physical exam if available.\",\n",
            "        \"Observations\": \"General health observations.\"\n",
            "    },\n",
            "    \"Assessment\": {\n",
            "        \"Diagnosis\": \"\",\n",
            "        \"Severity\": \"Mild, improving\"\n",
            "    },\n",
            "    \"Plan\": {\n",
            "        \"Treatment\": \"\",\n",
            "        \"Follow-Up\": \"Patient to return if symptoms persist or worsen.\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit transformers spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!curl -fsSL https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared\n",
        "!chmod +x cloudflared\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvqKb065Q6cg",
        "outputId": "a552852c-e109-40b8-ba0e-d77ad60b8d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.43.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "import json\n",
        "\n",
        "# Load NLP models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sentiment_pipeline = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Function for Named Entity Recognition (NER)\n",
        "def extract_medical_entities(text):\n",
        "    doc = nlp(text)\n",
        "    symptoms, treatments, diagnosis, prognosis = [], [], [], []\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"SYMPTOM\", \"DISEASE\"]:\n",
        "            symptoms.append(ent.text)\n",
        "        elif ent.label_ in [\"TREATMENT\", \"PROCEDURE\"]:\n",
        "            treatments.append(ent.text)\n",
        "        elif ent.label_ == \"DIAGNOSIS\":\n",
        "            diagnosis.append(ent.text)\n",
        "        elif ent.label_ == \"PROGNOSIS\":\n",
        "            prognosis.append(ent.text)\n",
        "\n",
        "    return {\n",
        "        \"Symptoms\": symptoms,\n",
        "        \"Treatments\": treatments,\n",
        "        \"Diagnosis\": diagnosis,\n",
        "        \"Prognosis\": prognosis\n",
        "    }\n",
        "\n",
        "# Function for Sentiment & Intent Analysis\n",
        "def analyze_sentiment(text):\n",
        "    result = sentiment_pipeline(text)[0]\n",
        "    label = result[\"label\"].lower()\n",
        "    sentiment = \"Neutral\"\n",
        "    intent = \"General statement\"\n",
        "\n",
        "    if \"neg\" in label:\n",
        "        sentiment = \"Anxious\"\n",
        "        intent = \"Seeking reassurance\"\n",
        "    elif \"pos\" in label:\n",
        "        sentiment = \"Reassured\"\n",
        "\n",
        "    return {\n",
        "        \"Sentiment\": sentiment,\n",
        "        \"Intent\": intent\n",
        "    }\n",
        "\n",
        "# Function for SOAP Note Generation\n",
        "def generate_soap_note(text):\n",
        "    entities = extract_medical_entities(text)\n",
        "    return {\n",
        "        \"Subjective\": {\n",
        "            \"Chief_Complaint\": entities[\"Symptoms\"],\n",
        "            \"History_of_Present_Illness\": text\n",
        "        },\n",
        "        \"Objective\": {\n",
        "            \"Physical_Exam\": \"Pending Examination\",\n",
        "            \"Observations\": \"Patient appears in normal health\"\n",
        "        },\n",
        "        \"Assessment\": {\n",
        "            \"Diagnosis\": entities[\"Diagnosis\"],\n",
        "            \"Severity\": \"Mild\"\n",
        "        },\n",
        "        \"Plan\": {\n",
        "            \"Treatment\": entities[\"Treatments\"],\n",
        "            \"Follow-Up\": \"Return if symptoms worsen.\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"ü©∫ Medical NLP Web App\")\n",
        "\n",
        "st.header(\"Enter Medical Transcript\")\n",
        "user_input = st.text_area(\"Paste the physician-patient conversation below:\")\n",
        "\n",
        "if st.button(\"Process Transcript\"):\n",
        "    if user_input.strip():\n",
        "        # Extracting Medical Details\n",
        "        entities = extract_medical_entities(user_input)\n",
        "        st.subheader(\"üìå Extracted Medical Information\")\n",
        "        st.json(entities)\n",
        "\n",
        "        # Sentiment & Intent Analysis\n",
        "        sentiment_analysis = analyze_sentiment(user_input)\n",
        "        st.subheader(\"üìä Sentiment & Intent Analysis\")\n",
        "        st.json(sentiment_analysis)\n",
        "\n",
        "        # SOAP Note Generation\n",
        "        soap_note = generate_soap_note(user_input)\n",
        "        st.subheader(\"üìù Generated SOAP Note\")\n",
        "        st.json(soap_note)\n",
        "    else:\n",
        "        st.warning(\"Please enter a valid transcript.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q6UubEERPz0",
        "outputId": "d8e27ad4-6462-4f9d-fa9c-0d9c5660e808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & ./cloudflared tunnel --url http://localhost:8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vHxFnPvRTHe",
        "outputId": "c9708bfd-573a-4225-fc3e-503e6aa2be88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-03-17T13:22:34Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-03-17T13:22:34Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.197.62.23:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m |  https://tips-louis-lawn-card.trycloudflare.com                                            |\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.2.1 (Checksum afdfadd1ef552e66bffc35246fe30a9bd578356d2d386de95585ccfc432472b8)\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.10, GoArch: amd64\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 5cd10289-ddca-416f-b7b9-ab450814ef43\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/run-tunnel/as-a-service/\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Using [CurveID(4588) CurveID(25497) CurveP256] as curve preferences \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193\n",
            "2025/03/17 13:22:37 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-03-17T13:22:37Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mdfcaf5ac-b233-4c82-af15-97a2afd7b7eb \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193 \u001b[36mlocation=\u001b[0mord08 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-03-17T13:22:58Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 41 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-17T13:22:58Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 41 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://tips-louis-lawn-card.trycloudflare.com/static/js/index.DmrHunjf.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-17T13:22:58Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 45 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-17T13:22:58Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 45 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://tips-louis-lawn-card.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-17T13:23:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 65 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-17T13:23:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 65 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://tips-louis-lawn-card.trycloudflare.com/static/js/index.DmrHunjf.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-17T13:23:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 73 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-17T13:23:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 73 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://tips-louis-lawn-card.trycloudflare.com/static/media/SourceSansPro-Bold.-6c9oR8J.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-17T13:23:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-17T13:23:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://tips-louis-lawn-card.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.193 \u001b[36mtype=\u001b[0mhttp\n",
            "2025-03-17 13:23:25.083480: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742217805.511648   32397 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742217805.628304   32397 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Device set to use cpu\n",
            "2025-03-17 13:23:38.803 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 345, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "2025-03-17 13:25:20.170 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 345, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Device set to use cpu\n",
            "2025-03-17 13:26:03.131 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 345, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Device set to use cpu\n",
            "2025-03-17 13:32:45.139 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 345, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    }
  ]
}